── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.3     ✔ purrr   0.3.4
✔ tibble  3.0.5     ✔ dplyr   1.0.3
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Loading required package: Rcpp
Loading 'brms' package (version 2.14.4). Useful instructions
can be found by typing help('brms'). A more detailed introduction
to the package is available through vignette('brms_overview').

Attaching package: ‘brms’

The following object is masked from ‘package:stats’:

    ar

// generated with brms 2.14.4
functions {
  /* turn a vector into a matrix of defined dimension 
   * stores elements in row major order
   * Args: 
   *   X: a vector 
   *   N: first dimension of the desired matrix
   *   K: second dimension of the desired matrix 
   * Returns: 
   *   a matrix of dimension N x K 
   */ 
  matrix as_matrix(vector X, int N, int K) { 
    matrix[N, K] Y; 
    for (i in 1:N) {
      Y[i] = to_row_vector(X[((i - 1) * K + 1):(i * K)]); 
    }
    return Y; 
  } 
 /* compute correlated group-level effects
  * Args: 
  *   z: matrix of unscaled group-level effects
  *   SD: vector of standard deviation parameters
  *   L: cholesky factor correlation matrix
  * Returns: 
  *   matrix of scaled group-level effects
  */ 
  matrix scale_r_cor(matrix z, vector SD, matrix L) {
    // r is stored in another dimension order than z
    return transpose(diag_pre_multiply(SD, L) * z);
  }
  /* Wiener diffusion log-PDF for a single response
   * Args: 
   *   y: reaction time data
   *   dec: decision data (0 or 1)
   *   alpha: boundary separation parameter > 0
   *   tau: non-decision time parameter > 0
   *   beta: initial bias parameter in [0, 1]
   *   delta: drift rate parameter
   * Returns:  
   *   a scalar to be added to the log posterior 
   */ 
   real wiener_diffusion_lpdf(real y, int dec, real alpha, 
                              real tau, real beta, real delta) { 
     if (dec == 1) {
       return wiener_lpdf(y | alpha, tau, beta, delta);
     } else {
       return wiener_lpdf(y | alpha, tau, 1 - beta, - delta);
     }
   }
}
data {
  int<lower=1> N;  // total number of observations
  vector[N] Y;  // response variable
  int<lower=0,upper=1> dec[N];  // decisions
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int<lower=1> K_bs;  // number of population-level effects
  matrix[N, K_bs] X_bs;  // population-level design matrix
  int<lower=1> K_bias;  // number of population-level effects
  matrix[N, K_bias] X_bias;  // population-level design matrix
  // data for group-level effects of ID 1
  int<lower=1> N_1;  // number of grouping levels
  int<lower=1> M_1;  // number of coefficients per level
  int<lower=1> J_1[N];  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_1_1;
  vector[N] Z_1_2;
  vector[N] Z_1_3;
  vector[N] Z_1_4;
  vector[N] Z_1_5;
  vector[N] Z_1_6;
  vector[N] Z_1_7;
  vector[N] Z_1_8;
  vector[N] Z_1_9;
  vector[N] Z_1_10;
  vector[N] Z_1_11;
  vector[N] Z_1_12;
  vector[N] Z_1_bs_13;
  vector[N] Z_1_bs_14;
  vector[N] Z_1_bs_15;
  vector[N] Z_1_ndt_16;
  vector[N] Z_1_bias_17;
  vector[N] Z_1_bias_18;
  vector[N] Z_1_bias_19;
  int<lower=1> NC_1;  // number of group-level correlations
  int prior_only;  // should the likelihood be ignored?
}
transformed data {
  real min_Y = min(Y);
}
parameters {
  vector[K] b;  // population-level effects
  vector[K_bs] b_bs;  // population-level effects
  real Intercept_ndt;  // temporary intercept for centered predictors
  vector[K_bias] b_bias;  // population-level effects
  vector<lower=0>[M_1] sd_1;  // group-level standard deviations
  matrix[M_1, N_1] z_1;  // standardized group-level effects
  cholesky_factor_corr[M_1] L_1;  // cholesky factor of correlation matrix
}
transformed parameters {
  matrix[N_1, M_1] r_1;  // actual group-level effects
  // using vectors speeds up indexing in loops
  vector[N_1] r_1_1;
  vector[N_1] r_1_2;
  vector[N_1] r_1_3;
  vector[N_1] r_1_4;
  vector[N_1] r_1_5;
  vector[N_1] r_1_6;
  vector[N_1] r_1_7;
  vector[N_1] r_1_8;
  vector[N_1] r_1_9;
  vector[N_1] r_1_10;
  vector[N_1] r_1_11;
  vector[N_1] r_1_12;
  vector[N_1] r_1_bs_13;
  vector[N_1] r_1_bs_14;
  vector[N_1] r_1_bs_15;
  vector[N_1] r_1_ndt_16;
  vector[N_1] r_1_bias_17;
  vector[N_1] r_1_bias_18;
  vector[N_1] r_1_bias_19;
  // compute actual group-level effects
  r_1 = scale_r_cor(z_1, sd_1, L_1);
  r_1_1 = r_1[, 1];
  r_1_2 = r_1[, 2];
  r_1_3 = r_1[, 3];
  r_1_4 = r_1[, 4];
  r_1_5 = r_1[, 5];
  r_1_6 = r_1[, 6];
  r_1_7 = r_1[, 7];
  r_1_8 = r_1[, 8];
  r_1_9 = r_1[, 9];
  r_1_10 = r_1[, 10];
  r_1_11 = r_1[, 11];
  r_1_12 = r_1[, 12];
  r_1_bs_13 = r_1[, 13];
  r_1_bs_14 = r_1[, 14];
  r_1_bs_15 = r_1[, 15];
  r_1_ndt_16 = r_1[, 16];
  r_1_bias_17 = r_1[, 17];
  r_1_bias_18 = r_1[, 18];
  r_1_bias_19 = r_1[, 19];
}
model {
  // likelihood including all constants
  if (!prior_only) {
    // initialize linear predictor term
    vector[N] mu = X * b;
    // initialize linear predictor term
    vector[N] bs = X_bs * b_bs;
    // initialize linear predictor term
    vector[N] ndt = Intercept_ndt + rep_vector(0.0, N);
    // initialize linear predictor term
    vector[N] bias = X_bias * b_bias;
    for (n in 1:N) {
      // add more terms to the linear predictor
      mu[n] += r_1_1[J_1[n]] * Z_1_1[n] + r_1_2[J_1[n]] * Z_1_2[n] + r_1_3[J_1[n]] * Z_1_3[n] + r_1_4[J_1[n]] * Z_1_4[n] + r_1_5[J_1[n]] * Z_1_5[n] + r_1_6[J_1[n]] * Z_1_6[n] + r_1_7[J_1[n]] * Z_1_7[n] + r_1_8[J_1[n]] * Z_1_8[n] + r_1_9[J_1[n]] * Z_1_9[n] + r_1_10[J_1[n]] * Z_1_10[n] + r_1_11[J_1[n]] * Z_1_11[n] + r_1_12[J_1[n]] * Z_1_12[n];
    }
    for (n in 1:N) {
      // add more terms to the linear predictor
      bs[n] += r_1_bs_13[J_1[n]] * Z_1_bs_13[n] + r_1_bs_14[J_1[n]] * Z_1_bs_14[n] + r_1_bs_15[J_1[n]] * Z_1_bs_15[n];
    }
    for (n in 1:N) {
      // add more terms to the linear predictor
      ndt[n] += r_1_ndt_16[J_1[n]] * Z_1_ndt_16[n];
    }
    for (n in 1:N) {
      // add more terms to the linear predictor
      bias[n] += r_1_bias_17[J_1[n]] * Z_1_bias_17[n] + r_1_bias_18[J_1[n]] * Z_1_bias_18[n] + r_1_bias_19[J_1[n]] * Z_1_bias_19[n];
    }
    for (n in 1:N) {
      // apply the inverse link function
      ndt[n] = exp(ndt[n]);
    }
    for (n in 1:N) {
      target += wiener_diffusion_lpdf(Y[n] | dec[n], bs[n], ndt[n], bias[n], mu[n]);
    }
  }
  // priors including all constants
  target += normal_lpdf(b | 0, 3);
  target += normal_lpdf(b_bs | 1.5, 1);
  target += normal_lpdf(Intercept_ndt | -5, 0.5);
  target += normal_lpdf(b_bias | 0.0, 0.5);
  target += student_t_lpdf(sd_1[1] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[2] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[3] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[4] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[5] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[6] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[7] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[8] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[9] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[10] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[11] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[12] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[13] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[14] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[15] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += normal_lpdf(sd_1[16] | 0, 0.01)
    - 1 * normal_lccdf(0 | 0, 0.01);
  target += student_t_lpdf(sd_1[17] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[18] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += student_t_lpdf(sd_1[19] | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
  target += std_normal_lpdf(to_vector(z_1));
  target += lkj_corr_cholesky_lpdf(L_1 | 1);
}
generated quantities {
  // actual population-level intercept
  real b_ndt_Intercept = Intercept_ndt;
  // compute group-level correlations
  corr_matrix[M_1] Cor_1 = multiply_lower_tri_self_transpose(L_1);
  vector<lower=-1,upper=1>[NC_1] cor_1;
  // extract upper diagonal of correlation matrix
  for (k in 1:M_1) {
    for (j in 1:(k - 1)) {
      cor_1[choose(k - 1, 2) + j] = Cor_1[j, k];
    }
  }
}
List of 35
 $ N          : int 11541
 $ Y          : num [1:11541(1d)] 5.03 3.43 3.21 3.05 4.42 ...
 $ dec        : num [1:11541(1d)] 0 0 0 0 0 1 0 0 0 0 ...
 $ K          : int 12
 $ X          : num [1:11541, 1:12] 1 1 1 1 0 0 1 1 1 1 ...
 $ Z_1_1      : num [1:11541(1d)] 1 1 1 1 0 0 1 1 1 1 ...
 $ Z_1_2      : num [1:11541(1d)] 0 0 0 0 1 1 0 0 0 0 ...
 $ Z_1_3      : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_4      : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_5      : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_6      : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_7      : num [1:11541(1d)] 2 1 1 2 0 0 1 1 3 1 ...
 $ Z_1_8      : num [1:11541(1d)] 0 0 0 0 3 3 0 0 0 0 ...
 $ Z_1_9      : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_10     : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_11     : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_12     : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ K_bs       : int 3
 $ X_bs       : num [1:11541, 1:3] 1 1 1 1 1 1 1 1 1 1 ...
 $ Z_1_bs_13  : num [1:11541(1d)] 1 1 1 1 1 1 1 1 1 1 ...
 $ Z_1_bs_14  : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_bs_15  : num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ K_ndt      : int 1
 $ X_ndt      : num [1:11541, 1] 1 1 1 1 1 1 1 1 1 1 ...
 $ Z_1_ndt_16 : num [1:11541(1d)] 1 1 1 1 1 1 1 1 1 1 ...
 $ K_bias     : int 3
 $ X_bias     : num [1:11541, 1:3] 1 1 1 1 1 1 1 1 1 1 ...
 $ Z_1_bias_17: num [1:11541(1d)] 1 1 1 1 1 1 1 1 1 1 ...
 $ Z_1_bias_18: num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ Z_1_bias_19: num [1:11541(1d)] 0 0 0 0 0 0 0 0 0 0 ...
 $ J_1        : int [1:11541(1d)] 1 1 1 1 1 1 1 1 1 1 ...
 $ N_1        : int 28
 $ M_1        : int 19
 $ NC_1       : int 171
 $ prior_only : int 0
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL '358de9a9c757080f631393d8366d26a6' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.11 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1100 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
