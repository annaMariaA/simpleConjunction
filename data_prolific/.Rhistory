#adding uncertainty around the mean
post <- extract.samples(m4.3)
prod(1+ runif(12,0,0.1))
replicate(1000,prod(1+ runif(12,0,0.1)))
growth <- replicate(1000,prod(1+ runif(12,0,0.1)))
dens(growth, norm.comp=TRUE)
library(rethinking)
dens(growth, norm.comp=TRUE)
growth <- replicate(1000,prod(1+ runif(12,0,0.5)))
dens(growth, norm.comp=TRUE)
growth <- replicate(1000,log(prod(1+ runif(12,0,0.5)))
)
dens(growth, norm.comp=TRUE)
313-279
install.packages("swirl")
library(swirl)
swirl()
swirl(4: Exploratory Data Analysis: The basics of exploring data in R)
swirl()
swirl()
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# standardize variables
d$D <- standardize( d$Divorce )
d$M <- standardize( d$Marriage )
d$A <- standardize( d$MedianAgeMarriage)
m5.1 <- quap(
alist( D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ) ) ,
data = d )
#To simulate from the priors, we can use extract.prior and linkas in the previous chapter
set.seed(10)
prior <- extract.prior( m5.1 )
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) )
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4)
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4)
)
#To simulate from the priors, we can use extract.prior and linkas in the previous chapter
set.seed(10)
prior <- extract.prior( m5.1 )
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) )
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
#(1) After I already know marriage rate ,what additional value is there in also knowing age at marriage?
#(2) After I already know age at marriage,what additional value is there in also knowing marriage rate?
m5.3 <- quap( alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ) ) ,
data = d )
#(1) After I already know marriage rate ,what additional value is there in also knowing age at marriage?
#(2) After I already know age at marriage,what additional value is there in also knowing marriage rate?
m5.3
precis( m5.3)
m5.4 <- quap( alist(
M ~ dnorm( mu , sigma ) ,
mu <- a + bAM * A ,
a ~ dnorm( 0 , 0.2 ) ,
bAM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ) ) , data = d )
precis(m5.4)
#thhe residuals are variation in marriage rate that is left over, after taking out the purely linear relationship between the two variables
mu <- link(m5.4)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- d$M - mu_mean
mu_resid
#plot predition from the data against simulated prediction
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
#compare the prediction to simulaed data
# call link without specifying new data # so it uses original data
mu <- link( m5.3 )
# summarize samples across cases
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI )
#let's now SIMULAE the predictions, averaging over the posterior
D_sim <- sim( m5.3 , n=1e4 )
D_PI <- apply( D_sim , 2 , PI)
#plot predition from the data against simulated prediction
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
#now we are adding both variables to the model
#we approximate the posterior
m5.7 <- quap( alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bN*N + bM*M ,
a ~ dnorm( 0 , 0.2 ) ,
bN ~ dnorm( 0 , 0.5 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ) ) ,
data=dcc )
precis(m5.7)
#first remove NaN
dcc <- d[ complete.cases(d$K,d$N,d$M) , ]
#now we are adding both variables to the model
#we approximate the posterior
m5.7 <- quap( alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bN*N + bM*M ,
a ~ dnorm( 0 , 0.2 ) ,
bN ~ dnorm( 0 , 0.5 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ) ) ,
data=dcc )
#looking at the relationship between milk caloric content, female body mass and percent of neocortex mass
library(rethinking)
data(milk)
d <- milk
str(d)
#standardize each variable to get a reliable approximation of the posterior and build reasonable prior
d$K <- standardize( d$kcal.per.g )
d$N <- standardize( d$neocortex.perc )
d$M <- standardize( log(d$mass) )
#first remove NaN
dcc <- d[ complete.cases(d$K,d$N,d$M) , ]
#first prior
m5.5_draft <- quap( alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bN*N ,
a ~ dnorm( 0 , 1 ) , #very big SD , change to 0.2
bN ~ dnorm( 0 , 1 ) ,#also very big SD, change to smaller 0.5
sigma ~ dexp( 1 ) ) ,
data=dcc )
#now posterior
precis(m5)
#now we are adding both variables to the model
#we approximate the posterior
m5.7 <- quap( alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bN*N + bM*M ,
a ~ dnorm( 0 , 0.2 ) ,
bN ~ dnorm( 0 , 0.5 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ) ) ,
data=dcc )
precis(m5.7)
#exploring categorical variables when there is more than 2
data(milk)
d <- milk
levels(d$clade)
#first the prior
K <- standardize( d$kcal.per.g )
m5.9 <- quap( alist(
K ~ dnorm( mu , sigma ),
mu <- a[clade_id], a[clade_id] ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
), data=d )
#coerce the factor to integer
d$clade_id <- as.integer( d$clade )
#first the prior
K <- standardize( d$kcal.per.g )
m5.9 <- quap(
alist(
K ~ dnorm( mu , sigma ),
mu <- a[clade_id], a[clade_id] ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
), data=d )
labels <- paste( "a[" , 1:4 , "]:" , levels(d$clade) , sep="" )
plot( precis( m5.9 , depth=2 , pars="a" ) ,
labels=labels , xlab="expected kcal (std)" )
library(ggplot2)
library(dplyr)
library(tidyr)
library(dplyr)
library(plyr)
library(readr)
library(tidyverse)
library(knitr)
library(kableExtra)
library(Rmisc)
library(broom)
mydir=setwd("C:/Users/Marcin/Documents/GitHub/dataLevel3/data_02_03_2021")
myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)
dat_csv = ldply(myfiles, read_csv)
dat_csv %>% dplyr::select(rt="key_resp.rt",accuracy="key_resp.corr",targetType="targetName",numDist="numDist",observer="participant",targetPres="targPres",age="age",sex="sex",n="trials.thisN")%>%
dplyr::filter(targetType=="greenverival" | targetType=="redHorizontal",
numDist!= 0 & numDist!= 1,
accuracy==1,
rt<3)%>%
dplyr::mutate(observer= as.character(observer))%>%
dplyr::filter(!observer %in% c("25","56","79"))%>%
dplyr::mutate(targetType = fct_recode(targetType, greenVertical = "greenverival", redHorizontal = "redHorizontal"),
observer= as.factor(observer),
targetType= as.factor(targetType),
targetPres= as.factor(targetPres),
numDist= as.factor(numDist),
numDist = fct_recode(numDist, "3" ="4",
"9"= "10",
"15"="16"),
numDist= as.numeric(as.character(numDist)),
observer = fct_recode(observer,"34"="Nathan Crush"))->totalDat
library(ggplot2)
library(dplyr)
library(tidyr)
library(dplyr)
library(plyr)
library(readr)
library(tidyverse)
library(knitr)
library(kableExtra)
library(Rmisc)
library(broom)
mydir=setwd("C:/Users/Marcin/Documents/GitHub/dataLevel3/data_02_03_2021")
myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)
dat_csv = ldply(myfiles, read_csv)
dat_csv %>% dplyr::select(rt="key_resp.rt",accuracy="key_resp.corr",targetType="targetName",numDist="numDist",observer="participant",targetPres="targPres",age="age",sex="sex",n="trials.thisN")%>%
dplyr::filter(targetType=="greenverival" | targetType=="redHorizontal",
numDist!= 0 & numDist!= 1,
accuracy==1,
rt<3)%>%
dplyr::mutate(observer= as.character(observer))%>%
dplyr::filter(!observer %in% c("25","56","79"))%>%
dplyr::mutate(targetType = fct_recode(targetType, greenVertical = "greenverival", redHorizontal = "redHorizontal"),
observer= as.factor(observer),
targetType= as.factor(targetType),
targetPres= as.factor(targetPres),
numDist= as.factor(numDist),
numDist = fct_recode(numDist, "3" ="4",
"9"= "10",
"15"="16"),
numDist= as.numeric(as.character(numDist)),
observer = fct_recode(observer,"34"="Nathan Crush"))->totalDat
#correlation test
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)
#correlation test
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)%>%
cor.test(greenVertical,redHorizontal)
#correlation test
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)->corr_RT
cor_test_RT <- cor.test(corr_RT$greenVertical,corr_RT$redHorizontal)
cor_test_RT
#correlation test
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::filter(targetPres=="1")%>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)->corr_RT
cor_test_RT <- cor.test(corr_RT$greenVertical,corr_RT$redHorizontal)
cor_test_RT
#correlation test
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::filter(targetPres=="0")%>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)->corr_RT
cor_test_RT <- cor.test(corr_RT$greenVertical,corr_RT$redHorizontal)
cor_test_RT
#correlation of reaction times between red and green
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)%>%
ggplot(aes(x=greenVertical, y=redHorizontal,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="rt red horizontal(s)", x="rt green vertical(s)", color="target position")+
xlim(0,2)   + ylim(0,2) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.8,0.15)) +geom_smooth(method=lm)->p_corr_rt
ggsave("C:/Users/Marcin/Documents/GitHub/dataLevel3/plots/correlation_rt.png", p_corr_rt, width = 5, height = 5)
p_corr_rt
#correlation of reaction times between red and green
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)%>%
ggplot(aes(x=greenVertical, y=redHorizontal,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="rt red horizontal(s)", x="rt green vertical(s)", color="target position")+
xlim(0,2)   + ylim(0,2) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.8,0.15)) +geom_smooth(method=lm)->p_corr_rt
p_corr_rt
ggsave("C:/Users/Marcin/Documents/GitHub/dataLevel3/plots/correlation_rt.png", p_corr_rt, width = 3, height = 3)
#correlation of reaction times between red and green
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)%>%
ggplot(aes(x=greenVertical, y=redHorizontal,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="rt red horizontal(s)", x="rt green vertical(s)", color="target position")+
xlim(0,2)   + ylim(0,2) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.78,0.18)) +geom_smooth(method=lm)->p_corr_rt
ggsave("C:/Users/Marcin/Documents/GitHub/dataLevel3/plots/correlation_rt.png", p_corr_rt, width = 3, height = 3)
#correlation of reaction times between red and green
totalDat %>% dplyr::group_by(targetType,observer,targetPres) %>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
dplyr::summarize(medianRT=median(rt),na.rm=TRUE)%>%
pivot_wider(
names_from = targetType,
values_from = medianRT)%>%
ggplot(aes(x=greenVertical, y=redHorizontal,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="rt red horizontal(s)", x="rt green vertical(s)", color="target position")+
xlim(0,2)   + ylim(0,2) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.78,0.18)) +geom_smooth(method=lm)->p_corr_rt
ggsave("C:/Users/Marcin/Documents/GitHub/dataLevel3/plots/correlation_rt.png", p_corr_rt, width = 3.5, height = 3.5)
fitted_models_red = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="redHorizontal")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
fitted_models_green = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="greenVertical")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
total_data <- merge(fitted_models_red, fitted_models_green,by=c("observer","targetPres"))%>%
ggplot(aes(x=estimate.x*100, y=estimate.y*100,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="slope red horizontal(ms)", x="slope green vertical(ms)", color="target position")+
xlim(0,6)   + ylim(0,6) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.8,0.15)) +geom_smooth(method=lm)->p_corr_slope
total_data <- merge(fitted_models_red, fitted_models_green,by=c("observer","targetPres"))%>%
ggplot(aes(x=estimate.x*100, y=estimate.y*100,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="slope red horizontal(ms)", x="slope green vertical(ms)", color="target position")+
xlim(0,6)   + ylim(0,6) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.78,0.18)) +geom_smooth(method=lm)->p_corr_slope
ggsave("C:/Users/Marcin/Documents/GitHub/dataLevel3/plots/correlation_slope.png", p_corr_slope, width = 3.5, height = 3.5)
fitted_models_red = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="redHorizontal")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
fitted_models_red
total_data <- merge(fitted_models_red, fitted_models_green,by=c("observer","targetPres"))%>%
ggplot(aes(x=estimate.x*100, y=estimate.y*100,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="slope red horizontal(ms)", x="slope green vertical(ms)", color="target position")+
xlim(0,6)   + ylim(0,6) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.78,0.18)) +geom_smooth(method=lm)->p_corr_slope
p_corr_slope
fitted_models_red = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="redHorizontal")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
fitted_models_green = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="greenVertical")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
total_data <- merge(fitted_models_red, fitted_models_green,by=c("observer","targetPres"))%>%
ggplot(aes(x=estimate.x*100, y=estimate.y*100,color=targetPres)) + geom_point(shape=1) +
scale_colour_hue(l=50) + # Use a slightly darker palette than normal
geom_smooth(method=lm,   # Add linear regression lines
se=FALSE,    # Don't add shaded confidence region
fullrange=TRUE) +
labs(y="slope red horizontal(ms)", x="slope green vertical(ms)", color="target position")+
xlim(0,6)   + ylim(0,6) + geom_abline(xintercept = 0, color="black", size=1, linetype=2)+
theme(legend.position=c(0.78,0.18)) +geom_smooth(method=lm)->p_corr_slope
p_corr_slope
total_data
total_data <- merge(fitted_models_red, fitted_models_green,by=c("observer","targetPres"))
head(total_data)
#intercept correlation
cor_test_slopes <- cor.test(fitted_models_red$estimate,fitted_models_green$estimate)
#intercept correlation
cor_test_slopes
fitted_models_red = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="redHorizontal",
targetPres=="absent")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
fitted_models_green = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="greenVertical",
targetPres=="absent")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
#intercept correlation
cor_test_slopes <- cor.test(fitted_models_red$estimate,fitted_models_green$estimate)
cor_test_slopes
fitted_models_red = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="redHorizontal",
targetPres=="present")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
fitted_models_green = totalDat %>% group_by(observer,targetType,targetPres)%>%
dplyr::mutate(targetPres = fct_recode(targetPres, absent = "0", present = "1"))%>%
filter(targetType=="greenVertical",
targetPres=="present")%>%
droplevels()%>%
do(model = lm(rt ~ numDist, data = .))%>%
tidy(model)%>%
filter(term=="numDist")
#intercept correlation
cor_test_slopes <- cor.test(fitted_models_red$estimate,fitted_models_green$estimate)
cor_test_slopes
cbPalette <- c("#4477AA", "#CC6677")#,"#4477AA", "#CC6677","#4477AA", "#CC6677","#4477AA", "#CC6677")#"#4477AA", "#CC6677")
library(ggplot2)
library(dplyr)
library(tidyr)
library(dplyr)
library(plyr)
library(readr)
library(tidyverse)
library(knitr)
library(kableExtra)
library(Rmisc)
mydir=setwd("C:/Users/Marcin/Documents/GitHub/simpleConjunction/data_collected_by_level_3")
myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)
dat_csv = ldply(myfiles, read_csv)
dat_csv %>% dplyr::select(rt="key_resp.rt",accuracy="key_resp.corr",targetType="targetName",numDist="numDist",observer="participant",targetPres="targPres",age="age",sex="sex",n="trials.thisN")%>%
dplyr::filter(targetType=="greenverival" | targetType=="redHorizontal" )%>%
dplyr::mutate(targetType = fct_recode(targetType, greenVertical = "greenverival", redHorizontal = "redHorizontal"),
observer= as.factor(observer),
targetType= as.factor(targetType),
targetPres= as.factor(targetPres),
numDist= as.factor(numDist),
numDist = fct_recode(numDist, "0" ="1",
"3" ="4",
"9"= "10",
"15"="16"),
observer = fct_recode(observer,"34"="Nathan Crush"))->totalDat
write.table(totaldat, "Rt_accuracy_extracted.txt", sep=",",row.names = F)
write.table(totalDat, "Rt_accuracy_extracted.txt", sep=",",row.names = F)
mydir=setwd("C:/Users/Marcin/Documents/GitHub/SimpleConjunction/data_pavlovia")
myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)
dat_csv = ldply(myfiles, read_csv)
dat_csv %>% dplyr::select(rt="key_resp.rt",accuracy="key_resp.corr",targetType="targetName",difficulty="difficulty",
n="trials.thisTrialN",observer="participant",targPresent="targPres")%>%
filter(n >= 0)%>%
dplyr::mutate(targetType = fct_recode(targetType, greenVertical = "greenverival",tex="texture"),
difficulty = fct_recode(difficulty, hard = "hard",  mid= "mid",easy="easy",
hard="tex_hard",easy="tex_easy",mid="tex_mid"),
observer= as.factor(observer),
targetType= as.factor(targetType),
difficulty= as.factor(difficulty))->totalDat
mydir=setwd("C:/Users/Marcin/Documents/GitHub/SimpleConjunction/data_pavlovia")
myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)
dat_csv = ldply(myfiles, read_csv)
dat_csv %>% dplyr::select(rt="key_resp.rt",accuracy="key_resp.corr",targetType="targetName",difficulty="difficulty",
n="trials.thisTrialN",observer="participant",targPresent="targPres")%>%
filter(n >= 0)%>%
dplyr::mutate(targetType = fct_recode(targetType, greenVertical = "greenverival",tex="texture"),
difficulty = fct_recode(difficulty, hard = "hard",  mid= "mid",easy="easy",
hard="tex_hard",easy="tex_easy",mid="tex_mid"),
observer= as.factor(observer),
targetType= as.factor(targetType),
difficulty= as.factor(difficulty))->totalDat
head(totalDat)
write.table(totalDat, "accuracy_rt_data.txt", sep=",",row.names = F)
