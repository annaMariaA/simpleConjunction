---
title: "Lvl3 Data"
author: "A Clarke"
date: "16/09/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggthemes)
library(brms)
library(tidybayes)
#library(corrr)
library(patchwork)

options(digits = 2, mc.cores = 10)

knitr::opts_chunk$set(echo = TRUE)
theme_set(theme_bw())

source("plot_ddm_model.R")
```

# Data check and merge

## Import Data

```{r}
d <- read_csv("../data_collected_by_level_3/Rt_accuracy_extracted.txt") %>%
  select(-age, -sex, -n) %>%
  select(obs = "observer", type = "targetType", targ = "targetPres", nD = "numDist", rt, accuracy) %>%
  mutate(targ = as_factor(targ),
         targ = fct_recode(targ, absent = "0", present = "1"),
         type = as_factor(type))
```



## Check Summary Statistics

### Removing Outliers

First of all, check overall accuracy per person and remove anybody with less than 75%.

```{r}
d %>% group_by(obs,  targ) %>%
  summarise(accuracy = mean(accuracy)) %>%
  filter(accuracy < 0.75) -> to_remove

to_remove %>% knitr::kable()
```

Looks like we should remove these two participants

```{r}
d <- filter(d, !(obs %in% unique(to_remove$obs)))
```


In this analysis, we only want to take the hardest ($nD = 15$) condition:

```{r}
d <- filter(d, nD == 15)
```

This is what we have left:

```{r}
summary(d) 
```


### Accuracy


Calculate accuracy per person and look at correlations.

```{r}
d %>% group_by(obs, type, targ) %>%
  summarise(accuracy = mean(accuracy)) %>%
  pivot_wider(names_from = "type", values_from = "accuracy") -> d_acc

ggplot(d_acc, aes(x = redHorizontal, y = greenVertical)) + 
  geom_abline(linetype = 2) + 
  geom_jitter(alpha = 0.5) +
  facet_wrap(~targ)
```

now check for correlations


```{r}
with(filter(d_acc, targ == "absent"),  cor.test(greenVertical, redHorizontal))
with(filter(d_acc, targ == "present"),  cor.test(greenVertical, redHorizontal))
```

### Reaction Times


Let's look at the RTs...

First, take out some outliers (the most extreme 1% of our data). 

```{r}
min_rt = quantile(d$rt, 0.005)
max_rt = quantile(d$rt, 0.995)

ggplot(d, aes(x = rt)) + geom_histogram(bins = 100) +
  geom_vline(xintercept = c(min_rt, max_rt), linetype = 2) +
  scale_x_log10() + 
  coord_cartesian(xlim = c(0.1, 10)) + 
  ggtitle("all RTs")


d <- filter(d, rt>min_rt, rt<max_rt)
```


Now we can look at correlations between median accuracy


```{r}
d %>% group_by(obs, type, targ) %>%
  summarise(rt = median(rt)) %>%
  pivot_wider(names_from = "type", values_from = "rt") -> d_rt

ggplot(d_rt, aes(x = redHorizontal, y = greenVertical)) + 
  geom_abline(linetype = 2) + 
  geom_jitter(alpha = 0.5) +
  facet_wrap(~targ)
```

now check for correlations

```{r}
with(filter(d_rt, targ == "absent"),  cor.test(greenVertical, redHorizontal))
with(filter(d_rt, targ == "present"),  cor.test(greenVertical, redHorizontal))
```


## Output for Modelling

We have already removed 
- the participants who were very inaccurate
- The bottom and top 0.5% of our data

Before we run our model, we have to recover the present/absent responses made for each trial (rather than accuracy)

```{r}
d$response <- NA
d$response[which(d$targ=="present" & d$accuracy==1)] = 1
d$response[which(d$targ=="present" & d$accuracy==0)] = 0
d$response[which(d$targ=="absent" & d$accuracy==1)] = 0
d$response[which(d$targ=="absent" & d$accuracy==0)] = 1
```

Finally, save the data before modelling.

```{r}
write_csv(d, "../cluster_level3/data_for_model.csv")
```


# Model 1 (full)


```{r}
m <- readRDS("models/level3_full.model")
```

## Posterior Predections

```{r}
d %>%
  mutate(obs = as.factor(obs)) -> d

# pred_wiener <- d %>% add_predicted_draws(m,negative_rt = TRUE, ndraws = 1) %>%
#   ungroup() %>%
#   select(-.chain, -.draw, -.iteration, -.row) %>%
#   mutate(rt = if_else(response == 1, rt, -rt)) %>%
#   pivot_longer(c(rt, .prediction), names_to = "emp_pre", values_to = "rt") %>%
#   select(-response, -accuracy) %>%
#   mutate(emp_pre = fct_recode(emp_pre, empirical = "rt", prediction = ".prediction"),
#                               response = if_else(rt < 0, "absent", "present"),
#                               response = as_factor(response),
#                               accuracy = response == targ,
#                               rt = abs(rt))
# write_csv(pred_wiener, "predictions_full.csv")

pred_wiener <- read_csv("predictions_full.csv")

ggplot(pred_wiener, aes(x = rt, colour = emp_pre)) + 
   geom_density(alpha = 0.5) + 
   facet_grid(nD~targ) +
   coord_cartesian(xlim = c(0, 2))

pred_wiener %>% group_by(obs, targ, type, nD, emp_pre) %>%
  summarise(median_rt = median(rt), .groups = "drop") %>%
  pivot_wider(names_from = "emp_pre", values_from = "median_rt") %>%
  mutate(abserr = abs(empirical - prediction)) -> dabserrt

pred_wiener %>% group_by(obs, targ, type, nD, emp_pre) %>%
  summarise(median_rt = median(rt), .groups = "drop") %>%
  pivot_wider(names_from = "emp_pre", values_from = "median_rt") %>%
  ggplot(aes(x = prediction, y = empirical, colour = type)) + 
  geom_abline(linetype = 2) +
  geom_point(alpha = 0.5) + 
  coord_fixed() + 
  scale_colour_manual(values = c("#228833", "#EE6677")) +
  facet_wrap(~targ) +
  theme(legend.position = "none") +
  ggtitle(paste("mean absoute error = ", round(mean(dabserrt$abserr),3), " seconds", sep="")) -> plt_rt



pred_wiener %>% group_by(obs, targ, type, nD, emp_pre) %>%
  summarise(accuracy = mean(accuracy), .groups = "drop") %>%
  pivot_wider(names_from = "emp_pre", values_from = "accuracy") %>%
  mutate(abserr = abs(empirical - prediction)) -> dabserr

pred_wiener %>% group_by(obs, targ, type, nD, emp_pre) %>%
  summarise(accuracy = mean(accuracy), .groups = "drop") %>%
  pivot_wider(names_from = "emp_pre", values_from = "accuracy") %>%
  ggplot(aes(x = prediction, y = empirical, colour = type)) + 
    geom_abline(linetype = 2) +
   scale_colour_manual(values = c("#228833", "#EE6677")) +
  facet_wrap(~targ) +
  coord_fixed(xlim = c(0.5, 1), ylim = c(0.5, 1)) + 
  geom_jitter(alpha = 0.25, height = 0.01)  +
  theme(legend.position = "none") +
  ggtitle(paste("mean absoute error = ", round(100*mean(dabserr$abserr),1), "%", sep="")) -> plt_acc


plt_acc / plt_rt

ggsave("../manuscript/figs/exp_lvl_3_pred.pdf", height = 6, width = 5)
```


```{r}
m %>% gather_draws(`cor.*`, regex = TRUE) %>%
  rename(var = ".variable") %>%
  mutate(var = str_remove(var, "cor_observer__")) -> cor_post 

cor_post %>% group_by(var) %>%
    summarise(p_not_zero = max(mean(.value > 0), mean(.value < 0))) %>%
    mutate(p_not_zero = cut(p_not_zero, c(0.5, 0.8, 0.9, 0.95, 0.99, 1))) %>%
    full_join(cor_post, by = "var") %>%
  select(-.chain, -.iteration , -.draw) -> cp
```

## Plot Parameters

```{r}
plt_rate_fx <- plot_model_params(m, "drift rate")
plt_rate_rn <- plt_cors(cp, "drift rate") 

plt_bs_fx <- plot_model_params(m, "bs")
plt_bs_rn <- plt_cors(cp, "bs") 

plt_bias_fx <- plot_model_params(m, "bias")
plt_bias_rn <- plt_cors(cp, "bias") 
```

```{r, fig.width=10}
(plt_rate_fx + plt_bs_fx + plt_bias_fx) / (plt_rate_rn + theme(legend.position = "none") + plt_bs_rn + plt_bias_rn)  + plot_layout(guides = "collect") & theme(legend.position = "none")
ggsave("model_output.png", width = 10, height = 5)
```


Make a table:

```{r}
cp_bs <- get_cor_data(cp, "bs")
cp_dr <- get_cor_data(cp, "drift rate")
cp_bias <- get_cor_data(cp, "bias")
    
bind_rows(cp_dr, cp_bs, cp_bias) %>%
  group_by( param, targ1) %>%
  median_hdci(.value) %>%
  knitr::kable()
    
```


